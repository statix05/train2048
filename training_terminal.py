#!/usr/bin/env python3
"""
Ğ¢ĞµÑ€Ğ¼Ğ¸Ğ½Ğ°Ğ»ÑŒĞ½Ğ°Ñ Ğ²ĞµÑ€ÑĞ¸Ñ Training GUI
ĞŸĞ¾ĞºĞ°Ğ·Ñ‹Ğ²Ğ°ĞµÑ‚ Ğ¿Ñ€Ğ¾Ğ³Ñ€ĞµÑÑ Ğ¾Ğ±ÑƒÑ‡ĞµĞ½Ğ¸Ñ Ğ² ĞºĞ¾Ğ½ÑĞ¾Ğ»Ğ¸ Ñ Ğ¾Ğ±Ğ½Ğ¾Ğ²Ğ»ĞµĞ½Ğ¸ĞµĞ¼ Ğ² Ñ€ĞµĞ°Ğ»ÑŒĞ½Ğ¾Ğ¼ Ğ²Ñ€ĞµĞ¼ĞµĞ½Ğ¸
"""
import os
import sys
import time
import numpy as np
from collections import deque
from typing import List, Tuple

from game_2048 import Game2048, Direction
from neural_network import DQNAgent, device
from trainer import Trainer


class TerminalTrainingDisplay:
    """ĞÑ‚Ğ¾Ğ±Ñ€Ğ°Ğ¶ĞµĞ½Ğ¸Ğµ Ğ¾Ğ±ÑƒÑ‡ĞµĞ½Ğ¸Ñ Ğ² Ñ‚ĞµÑ€Ğ¼Ğ¸Ğ½Ğ°Ğ»Ğµ"""
    
    def __init__(self):
        self.score_history = deque(maxlen=50)
        self.tile_history = deque(maxlen=50)
        self.loss_history = deque(maxlen=50)
    
    def clear_screen(self):
        """ĞÑ‡Ğ¸ÑÑ‚ĞºĞ° ÑĞºÑ€Ğ°Ğ½Ğ°"""
        os.system('clear' if os.name == 'posix' else 'cls')
    
    def draw_progress_bar(self, progress: float, width: int = 40) -> str:
        """Ğ Ğ¸ÑĞ¾Ğ²Ğ°Ğ½Ğ¸Ğµ Ğ¿Ñ€Ğ¾Ğ³Ñ€ĞµÑÑ-Ğ±Ğ°Ñ€Ğ°"""
        filled = int(width * progress)
        bar = 'â–ˆ' * filled + 'â–‘' * (width - filled)
        return f"[{bar}] {progress*100:.1f}%"
    
    def draw_mini_graph(self, data: List[float], width: int = 50, height: int = 8) -> List[str]:
        """Ğ Ğ¸ÑĞ¾Ğ²Ğ°Ğ½Ğ¸Ğµ Ğ¼Ğ¸Ğ½Ğ¸-Ğ³Ñ€Ğ°Ñ„Ğ¸ĞºĞ°"""
        if len(data) < 2:
            return [" " * width] * height
        
        min_val = min(data)
        max_val = max(data)
        range_val = max_val - min_val if max_val > min_val else 1
        
        lines = []
        for h in range(height):
            line = ""
            threshold = 1.0 - (h / height)
            
            for i, val in enumerate(data[-width:]):
                normalized = (val - min_val) / range_val
                if normalized >= threshold:
                    line += "â–ˆ"
                elif normalized >= threshold - (1.0 / height):
                    line += "â–“"
                else:
                    line += " "
            
            lines.append(line)
        
        return lines
    
    def draw_board(self, board: np.ndarray) -> str:
        """Ğ Ğ¸ÑĞ¾Ğ²Ğ°Ğ½Ğ¸Ğµ Ğ¸Ğ³Ñ€Ğ¾Ğ²Ğ¾Ğ³Ğ¾ Ğ¿Ğ¾Ğ»Ñ"""
        lines = []
        lines.append("â”Œâ”€â”€â”€â”€â”¬â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”")
        
        for i in range(4):
            row = "â”‚"
            for j in range(4):
                val = board[i, j]
                if val == 0:
                    row += " Â·  â”‚"
                elif val < 1000:
                    row += f"{val:^4}â”‚"
                else:
                    row += f"{val:4}â”‚"
            lines.append(row)
            
            if i < 3:
                lines.append("â”œâ”€â”€â”€â”€â”¼â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”¤")
        
        lines.append("â””â”€â”€â”€â”€â”´â”€â”€â”€â”€â”´â”€â”€â”€â”€â”´â”€â”€â”€â”€â”˜")
        return "\n".join(lines)
    
    def display(self, episode: int, total_episodes: int, 
                game: Game2048, stats: dict):
        """ĞŸĞ¾Ğ»Ğ½Ğ¾Ğµ Ğ¾Ğ±Ğ½Ğ¾Ğ²Ğ»ĞµĞ½Ğ¸Ğµ Ğ´Ğ¸ÑĞ¿Ğ»ĞµÑ"""
        self.clear_screen()
        
        # Ğ—Ğ°Ğ³Ğ¾Ğ»Ğ¾Ğ²Ğ¾Ğº
        print("=" * 70)
        print(" " * 20 + "ğŸ§  2048 AI TRAINING")
        print("=" * 70)
        print()
        
        # ĞŸÑ€Ğ¾Ğ³Ñ€ĞµÑÑ
        progress = episode / total_episodes
        print(f"Episode: {episode:,} / {total_episodes:,}")
        print(self.draw_progress_bar(progress))
        print()
        
        # Ğ”Ğ²Ğµ ĞºĞ¾Ğ»Ğ¾Ğ½ĞºĞ¸: Ğ¸Ğ³Ñ€Ğ¾Ğ²Ğ¾Ğµ Ğ¿Ğ¾Ğ»Ğµ Ğ¸ ÑÑ‚Ğ°Ñ‚Ğ¸ÑÑ‚Ğ¸ĞºĞ°
        board_str = self.draw_board(game.board)
        board_lines = board_str.split('\n')
        
        stats_lines = [
            "â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—",
            "â•‘    CURRENT GAME          â•‘",
            "â• â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•£",
            f"â•‘ Score:      {game.score:>12} â•‘",
            f"â•‘ Max Tile:   {game.max_tile:>12} â•‘",
            f"â•‘ Moves:      {game.moves:>12} â•‘",
            "â• â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•£",
            "â•‘    STATISTICS            â•‘",
            "â• â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•£",
            f"â•‘ Avg Score:  {stats['avg_score']:>12.0f} â•‘",
            f"â•‘ Avg Tile:   {stats['avg_max_tile']:>12.0f} â•‘",
            f"â•‘ Best Score: {stats['best_score']:>12} â•‘",
            f"â•‘ Best Tile:  {stats['best_max_tile']:>12} â•‘",
            "â• â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•£",
            "â•‘    TRAINING              â•‘",
            "â• â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•£",
            f"â•‘ Loss:       {stats['loss']:>12.4f} â•‘",
            f"â•‘ Epsilon:    {stats['epsilon']:>12.3f} â•‘",
            "â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•",
        ]
        
        # Ğ’Ñ‹Ğ²Ğ¾Ğ´Ğ¸Ğ¼ Ğ¿Ğ°Ñ€Ğ°Ğ»Ğ»ĞµĞ»ÑŒĞ½Ğ¾
        max_lines = max(len(board_lines), len(stats_lines))
        for i in range(max_lines):
            board_line = board_lines[i] if i < len(board_lines) else " " * 25
            # Pad board_line to fixed width to ensure right column is aligned
            # The board uses box drawing chars which might mess up len() if not careful,
            # but here they are 1-char width. 
            # The board width is 4 cells * 5 chars/cell + 1 char (start) + 1 char (end) = 22?
            # Let's check draw_board: 
            # "â”Œâ”€â”€â”€â”€â”¬â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”" -> len is 21
            # "â”‚ 16 â”‚ 8  â”‚ 16 â”‚ 2  â”‚" -> len is 21
            # So we pad to 25
            
            # Clean padding using ljust with exact known width of board string (21)
            # Use a slightly larger padding to separate columns
            padding_len = 26 
            
            # Calculate visible length (len() works for these chars)
            current_len = len(board_line)
            padding = " " * (padding_len - current_len)
            
            stats_line = stats_lines[i] if i < len(stats_lines) else ""
            print(f"  {board_line}{padding}{stats_line}")
        
        print()
        
        # Ğ“Ñ€Ğ°Ñ„Ğ¸ĞºĞ¸
        if len(self.score_history) > 1:
            print("â•”" + "â•" * 68 + "â•—")
            print("â•‘" + " " * 25 + "SCORE HISTORY" + " " * 30 + "â•‘")
            print("â• " + "â•" * 68 + "â•£")
            
            graph_lines = self.draw_mini_graph(list(self.score_history), width=66)
            for line in graph_lines:
                print(f"â•‘ {line} â•‘")
            
            if len(self.score_history) >= 2:
                min_score = min(self.score_history)
                max_score = max(self.score_history)
                print(f"â•‘  Min: {min_score:>6.0f}  Max: {max_score:>6.0f}  Current: {stats['avg_score']:>6.0f}" + " " * 24 + "â•‘")
            
            print("â•š" + "â•" * 68 + "â•")
        
        print()
        print("Press Ctrl+C to stop training")
        print()


def train_terminal(n_episodes: int = 1000, 
                   learning_rate: float = 1e-4,
                   batch_size: int = 64,
                   buffer_size: int = 50000,
                   model_type: str = 'dueling',
                   game_mode: str = 'classic'):
    """ĞĞ±ÑƒÑ‡ĞµĞ½Ğ¸Ğµ Ñ Ñ‚ĞµÑ€Ğ¼Ğ¸Ğ½Ğ°Ğ»ÑŒĞ½Ñ‹Ğ¼ Ğ¸Ğ½Ñ‚ĞµÑ€Ñ„ĞµĞ¹ÑĞ¾Ğ¼"""
    
    print(f"Starting training on device: {device}")
    print(f"Episodes: {n_episodes}")
    print(f"Model Type: {model_type}")
    print(f"Game Mode: {game_mode}")
    print()
    
    # Ğ¡Ğ¾Ğ·Ğ´Ğ°Ğ½Ğ¸Ğµ Ğ°Ğ³ĞµĞ½Ñ‚Ğ°
    agent = DQNAgent(
        learning_rate=learning_rate,
        buffer_size=buffer_size,
        batch_size=batch_size,
        epsilon_decay=n_episodes * 5,
        model_type=model_type
    )
    
    trainer = Trainer(agent)
    display = TerminalTrainingDisplay()
    
    # ĞĞºĞ½Ğ° Ğ´Ğ»Ñ ÑÑ‚Ğ°Ñ‚Ğ¸ÑÑ‚Ğ¸ĞºĞ¸
    score_window = deque(maxlen=10)
    tile_window = deque(maxlen=10)
    moves_window = deque(maxlen=10)
    
    try:
        for episode in range(1, n_episodes + 1):
            # ĞĞ´Ğ¸Ğ½ ÑĞ¿Ğ¸Ğ·Ğ¾Ğ´
            game = Game2048(mode=game_mode)
            result = trainer.train_episode(game)
            
            # ĞĞ±Ğ½Ğ¾Ğ²Ğ»ÑĞµĞ¼ Ğ¾ĞºĞ½Ğ°
            score_window.append(result['score'])
            tile_window.append(result['max_tile'])
            moves_window.append(result['moves'])
            
            # ĞĞ±Ğ½Ğ¾Ğ²Ğ»ÑĞµĞ¼ Ğ»ÑƒÑ‡ÑˆĞ¸Ğµ Ñ€ĞµĞ·ÑƒĞ»ÑŒÑ‚Ğ°Ñ‚Ñ‹
            if result['score'] > trainer.best_score:
                trainer.best_score = result['score']
            if result['max_tile'] > trainer.best_max_tile:
                trainer.best_max_tile = result['max_tile']
            
            # Ğ”Ğ¾Ğ±Ğ°Ğ²Ğ»ÑĞµĞ¼ Ğ² Ğ¸ÑÑ‚Ğ¾Ñ€Ğ¸Ñ Ğ´Ğ»Ñ Ğ³Ñ€Ğ°Ñ„Ğ¸ĞºĞ°
            display.score_history.append(np.mean(score_window))
            display.tile_history.append(np.mean(tile_window))
            if result['loss'] > 0:
                display.loss_history.append(result['loss'])
            
            # ĞĞ±Ğ½Ğ¾Ğ²Ğ»ÑĞµĞ¼ Ğ´Ğ¸ÑĞ¿Ğ»ĞµĞ¹
            if episode % 5 == 0 or episode == 1:
                stats = {
                    'avg_score': np.mean(score_window),
                    'avg_max_tile': np.mean(tile_window),
                    'avg_moves': np.mean(moves_window),
                    'best_score': trainer.best_score,
                    'best_max_tile': trainer.best_max_tile,
                    'loss': result['loss'],
                    'epsilon': agent.get_epsilon()
                }
                
                display.display(episode, n_episodes, game, stats)
                time.sleep(0.05)  # ĞĞµĞ±Ğ¾Ğ»ÑŒÑˆĞ°Ñ Ğ·Ğ°Ğ´ĞµÑ€Ğ¶ĞºĞ° Ñ‡Ñ‚Ğ¾Ğ±Ñ‹ Ğ²Ğ¸Ğ´ĞµÑ‚ÑŒ Ğ¾Ğ±Ğ½Ğ¾Ğ²Ğ»ĞµĞ½Ğ¸Ñ
            
            # Ğ¡Ğ¾Ñ…Ñ€Ğ°Ğ½ĞµĞ½Ğ¸Ğµ ĞºĞ°Ğ¶Ğ´Ñ‹Ğµ 100 ÑĞ¿Ğ¸Ğ·Ğ¾Ğ´Ğ¾Ğ²
            if episode % 100 == 0:
                trainer.save_checkpoint(episode)
                print(f"\nğŸ’¾ Model saved at episode {episode}")
                time.sleep(1)
        
        # Ğ¤Ğ¸Ğ½Ğ°Ğ»ÑŒĞ½Ğ¾Ğµ ÑĞ¾Ñ…Ñ€Ğ°Ğ½ĞµĞ½Ğ¸Ğµ
        trainer.save_checkpoint(n_episodes, final=True)
        
        display.clear_screen()
        print("=" * 70)
        print(" " * 25 + "ğŸ‰ TRAINING COMPLETE!")
        print("=" * 70)
        print()
        print(f"Total Episodes: {n_episodes:,}")
        print(f"Best Score: {trainer.best_score:,}")
        print(f"Best Max Tile: {trainer.best_max_tile}")
        print()
        print("Model saved to: models/model_final.pt")
        print("Best model saved to: models/model_best.pt")
        print()
        print("Try your trained model:")
        print("  python main.py play --ai")
        print("  python gui_terminal.py --ai")
        print()
    
    except KeyboardInterrupt:
        print("\n\nâ¹ï¸  Training interrupted by user")
        trainer.save_checkpoint(episode)
        print(f"Progress saved at episode {episode}")


def main():
    """Ğ“Ğ»Ğ°Ğ²Ğ½Ğ°Ñ Ñ„ÑƒĞ½ĞºÑ†Ğ¸Ñ"""
    import argparse
    
    parser = argparse.ArgumentParser(description="Terminal Training Interface")
    parser.add_argument('--episodes', type=int, default=1000, help='Number of episodes')
    parser.add_argument('--lr', type=float, default=1e-4, help='Learning rate')
    parser.add_argument('--batch-size', type=int, default=64, help='Batch size')
    parser.add_argument('--buffer-size', type=int, default=50000, help='Buffer size')
    parser.add_argument('--model', type=str, default='dueling', choices=['simple', 'conv', 'dueling', 'hybrid'], help='Neural Network Architecture')
    
    args = parser.parse_args()
    
    train_terminal(
        n_episodes=args.episodes,
        learning_rate=args.lr,
        batch_size=args.batch_size,
        buffer_size=args.buffer_size,
        model_type=args.model
    )


if __name__ == "__main__":
    main()
